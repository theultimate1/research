{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: window was already closed\n  (Session info: chrome=78.0.3904.70)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a9f0d09bd703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mlogin_twitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_twitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mscrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a9f0d09bd703>\u001b[0m in \u001b[0;36mscrapper\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m#call dynamic page scroll function here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_scroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a9f0d09bd703>\u001b[0m in \u001b[0;36mtweet_scroller\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m#define how many seconds to wait while dynamic page content loads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mnewHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"return document.body.scrollHeight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewHeight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlastHeight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[0;34m(self, script, *args)\u001b[0m\n\u001b[1;32m    634\u001b[0m         return self.execute(command, {\n\u001b[1;32m    635\u001b[0m             \u001b[0;34m'script'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             'args': converted_args})['value']\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: window was already closed\n  (Session info: chrome=78.0.3904.70)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import pprint as pp\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "def login_twitter(driver, username, password):\n",
    " \n",
    "    # open the web page in the browser:\n",
    "    driver.get(\"https://twitter.com/login\")\n",
    " \n",
    "    # find the boxes for username and password\n",
    "    username_field = driver.find_element_by_class_name(\"js-username-field\")\n",
    "    password_field = driver.find_element_by_class_name(\"js-password-field\")\n",
    " \n",
    "    # enter your username:\n",
    "    username_field.send_keys(username)\n",
    "    driver.implicitly_wait(1)\n",
    " \n",
    "    # enter your password:\n",
    "    password_field.send_keys(password)\n",
    "    driver.implicitly_wait(1)\n",
    " \n",
    "    # click the \"Log In\" button:\n",
    "    driver.find_element_by_class_name(\"EdgeButtom--medium\").click()\n",
    "    \n",
    "    return\n",
    "def search_twitter(driver, query):\n",
    " \n",
    "    # wait until the search box has loaded:\n",
    "    #box = driver.wait.until(EC.presence_of_element_located((By.NAME, \"q\")))\n",
    " \n",
    "    # find the search box in the html:\n",
    "    box=driver.find_element_by_xpath(\"//input[@placeholder='Search Twitter']\")\n",
    "    box.click()\n",
    "    # enter your search string in the search box:\n",
    "    box.send_keys(query)\n",
    " \n",
    "    # submit the query (like hitting return):\n",
    "    box.submit()\n",
    " \n",
    "    # initial wait for the search results to load\n",
    "    driver.implicitly_wait(5)\n",
    "    url=driver.current_url\n",
    "    return url\n",
    "\n",
    "#url =\"https://twitter.com/search?q=pollution%20exclude%3Aretweets&src=typed_query\"  #eg: https://www.twitter.com/xyz/\n",
    "\n",
    "#this function is to handle dynamic page content loading - using Selenium\n",
    "def tweet_scroller(url):\n",
    "\n",
    "    browser.get(url)\n",
    "    \n",
    "    #define initial page height for 'while' loop\n",
    "    lastHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        #define how many seconds to wait while dynamic page content loads\n",
    "        time.sleep(3)\n",
    "        newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if newHeight == lastHeight:\n",
    "            break\n",
    "        else:\n",
    "            lastHeight = newHeight\n",
    "            \n",
    "    html = browser.page_source\n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "    \n",
    "#function to handle/parse HTML and extract data - using BeautifulSoup    \n",
    "def scrapper(url):\n",
    "    \n",
    "    #regex patterns\n",
    "    url_finder = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    problemchars = re.compile(r'[\\[=\\+/&<>;:!\\\\|*^\\'\"\\?%$@)(_\\,\\.\\t\\r\\n0-9-â€”\\]]')\n",
    "    prochar = '[(=\\-\\+\\:/&<>;|\\'\"\\?%#$@\\,\\._)]'\n",
    "    crp = re.compile(r'MoreCopy link to TweetEmbed Tweet|Reply')\n",
    "    retweet = re.compile(r\"(?<=Retweet:)(.*)(?=', u'R)\")\n",
    "    fave = re.compile(r\"(?<=Like:)(.*)(?=', u'Liked)\")\n",
    "    wrd = re.compile(r'[A-Z]+[a-z]*')\n",
    "    dgt = re.compile(r'\\d+')    \n",
    "    \n",
    "\n",
    "    blog_list = []\n",
    "     \n",
    "    #set to global in case you want to play around with the HTML later   \n",
    "    global soup    \n",
    "    \n",
    "    #call dynamic page scroll function here\n",
    "    soup = BeautifulSoup(tweet_scroller(url), \"html.parser\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    for i in soup.find_all('li', {\"data-item-type\":\"tweet\"}):\n",
    "        user = (i.find('span', {'class':\"username js-action-profile-name\"}).get_text() if i.find('span', {'class':\"username js-action-profile-name\"}) is not None else \"\")\n",
    "        link = ('https://twitter.com' + i.small.a['href'] if i.small is not None else \"\")\n",
    "        date = (i.small.a['title'] if i.small is not None else \"\")\n",
    "        popular = (i.find('div', {'class': \"js-tweet-text-container\"}).get_text().replace('\\n','') if i.find('div', {'class': \"js-tweet-text-container\"}) is not None else \"\")\n",
    "        text = (i.p.get_text().replace('\\n','') if i.p is not None else \"\")\n",
    "        popular_text = [i + ':' + j  if len(dgt.findall(popular)) != 0 else '' for i, j in zip(wrd.findall(crp.sub('', popular)), dgt.findall(popular))]\n",
    "        \n",
    "            \n",
    "            #build dictionary to format data as key-pair value \n",
    "        blog_dict = {\n",
    "        \"header\": \"twitter_hashtag_\" + url.rsplit('/',2)[1],\n",
    "        \"url\": link,\n",
    "        \"user\": user,\n",
    "        \"date\": date,\n",
    "        \"popular\": popular_text,\n",
    "            #before text is stored URLs are removed - note: hash symbol is maintained to indicate hashtag term\n",
    "        \"blog_text\": problemchars.sub(' ', url_finder.sub('', text)),\n",
    "        \"like_fave\": (int(''.join(fave.findall(str(popular_text)))) if len(fave.findall(str(popular_text))) > 0 else ''),\n",
    "        \"share_retweet\": (int(''.join(retweet.findall(str(popular_text)))) if len(retweet.findall(str(popular_text))) > 0 else '')\n",
    "        }\n",
    "        \n",
    "        blog_list.append(blog_dict)            \n",
    "        \n",
    "            \n",
    "    #call csv writer function and output file\n",
    "    writer_csv_3(blog_list)\n",
    "    \n",
    "    return pp.pprint(blog_list[0:2])\n",
    "\n",
    "    \n",
    "    \n",
    "#function to write CSV file\n",
    "def writer_csv_3(blog_list):\n",
    "    \n",
    "    #uses group name from URL to construct output file name\n",
    "    file_out = \"twitter_hashtag_{page}.csv\".format(page = url.rsplit('/',2)[1])\n",
    "    \n",
    "    with io.open(file_out, \"w\", encoding=\"utf-8\") as csvfile:\n",
    "\n",
    "        writer = csv.writer(csvfile, lineterminator='\\n', delimiter=',', quotechar='\"')\n",
    "    \n",
    "        for i in blog_list:\n",
    "            if len(i['blog_text']) > 0:\n",
    "                newrow = i['header'], i['url'], i['user'], i['date'], i[\"popular\"],i[\"blog_text\"] ,i[\"like_fave\"], i[\"share_retweet\"]\n",
    "\n",
    "                writer.writerow(newrow)                     \n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    \n",
    "#main\n",
    "if __name__ == \"__main__\":\n",
    "    path_to_chromedriver =\"/Users/aakashvardhan/Downloads/chromedriver\"            #enter path of chromedriver\n",
    "    browser = webdriver.Chrome(executable_path = path_to_chromedriver)\n",
    "    query=\"water exclude:retweets\"\n",
    "    username = \"vardhan_aakash1\"\n",
    "    password = \"Galgaddot8763\"\n",
    "    login_twitter(browser, username, password)\n",
    "    url=search_twitter(browser,query)\n",
    "    scrapper(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-env",
   "language": "python",
   "name": "research-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
