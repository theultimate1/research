{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "'''Used to help format and organize the messy web by fixing bad HTML and presenting us with\n",
    "easily-traversible Python objects repreenting XML structures.'''\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from unidecode import unidecode\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    def __init__(self):\n",
    "        #Twitter Credentials\n",
    "        with open('twitter_cred.json') as secret_info:\n",
    "            info = json.load(secret_info)\n",
    "            consumer_key = info['CONSUMER_KEY']\n",
    "            consumer_secret = info['CONSUMER_SECRET']\n",
    "            access_key = info['ACCESS_KEY']\n",
    "            access_secret = info['ACCESS_SECRET']\n",
    "            \n",
    "            try:\n",
    "\n",
    "                # Creating the API endpoint\n",
    "                auth = tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "                #setting the access token and secret\n",
    "                auth.set_access_token(access_key,access_secret)\n",
    "                self.api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "            except tweepy.TweepError as e:\n",
    "                print(f\"Error: Twitter Authentication Failed - \\n{str(e)}\")\n",
    "    \n",
    "    #Function used to fetch tweets\n",
    "    def get_tweets(self,query,maxTweets = 1000):\n",
    "        tweets = []\n",
    "        sinceId = []\n",
    "        max_id = -1\n",
    "        tweetCount = 0\n",
    "        tweetsPerQry = 100\n",
    "        date_since = \"2019-01-11\"\n",
    "        \n",
    "        while tweetCount < maxTweets:\n",
    "            try:\n",
    "#                 if (max_id <= 0):\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = self.api.search(q=query,count=tweetsPerQry)\n",
    "#                     else:\n",
    "#                         new_tweets = self.api.search(q=query,count=tweetsPerQry,since_id = sinceId)\n",
    "#                 else:\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = self.api.search(q=query,count=tweetsPerQry,max_id=str(max_id-1))\n",
    "#                     else:\n",
    "#                         new_tweets = self.api.search(q=query,count=tweetsPerQry,max_id=str(max_id-1),since_id=sinceId)\n",
    "                new_tweets = tweepy.Cursor(self.api.search,\n",
    "                   q=query,\n",
    "                  lang='en',\n",
    "                  since=date_since).items(tweetsPerQry)\n",
    "                if not new_tweets:\n",
    "                    print(\"No more tweets found\")\n",
    "                    break\n",
    "                \n",
    "                for tweet in new_tweets:\n",
    "                    parsed_tweet = {}\n",
    "                    parsed_tweet['tweets'] = tweet.text\n",
    "                    \n",
    "                    #Appending parsed tweets to tweets list\n",
    "                    if tweet.retweet_count > 0:\n",
    "                        #if the tweet has retweets, ensure that it is appended only once\n",
    "                        if parsed_tweet and not 'RT @' not in tweets:\n",
    "                            tweets.append(parsed_tweet)\n",
    "                    else:\n",
    "                        tweets.append(parsed_tweet)\n",
    "#                 tweetCount += len(new_tweets)\n",
    "#                 print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "#                 max_id = new_tweets[-1].id\n",
    "            except tweepy.TweepError as e:\n",
    "                print(\"Tweepy error:\" + str(e))\n",
    "                break\n",
    "        t = pd.DataFrame(tweets)\n",
    "        t.columns = ['List of Tweets']\n",
    "        with open('tweets_pull5.csv','a+') as f:\n",
    "            t.to_csv(f,header=['List of Tweets'])\n",
    "        return t\n",
    "    \n",
    "    def remove_pattern(text,pattern_regex):\n",
    "        r = re.findall(pattern_regex,text)\n",
    "        for i in r:\n",
    "            text = re.sub(i,'',text)\n",
    "        return text\n",
    "    \n",
    "                        \n",
    "                        \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#algaebloom OR #chemicalspill OR #drinkingwatercontamination-filter:retweets\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e97a1825f562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnew_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_terms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-filter:retweets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_search\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtweets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselenium_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_search\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-76195572bbe7>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(self, query, maxTweets)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0mparsed_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mparsed_tweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-env/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                                         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rate limit reached. Sleeping for: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sleep for few extra sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;31m# if self.wait_on_rate_limit and self._reset_time is not None and \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "selenium_client = TwitterClient()\n",
    "# l = ['#algaebloom', '#chemicalspill', '#drinkingwatercontamination', '#drought', '#drywell', '#ecoli', '#flashflood', '#groundwatercontamination', '#industrialpollution', '#oilspill', '#pipeleak', '#wastewater', '#waterandsanitation', '#watercontamination', '#watermanagement', '#waterpollution', 'algae bloom', 'beach closure', 'chemical spill', 'coal ash water', 'drinking water', 'drinking water contamination', 'drought', 'dry well', 'e-coli', 'ecoli', 'flash flood', 'flood warning', 'groundwater contamination', 'groundwater pollution', 'industrial pollution', 'industrial solvents', 'lake contamination', 'lake pollution', 'lead water', 'marine plastic pollution', 'metal hydroxide', 'oil spill', 'oxygen depletion', 'pipe leak', 'point source pollution', 'river contamination', 'stream contamination', 'surface water contamination', 'toxic waste water', 'untreated waste', 'waste spill', 'waste water', 'water and sanitation', 'water bacteria', 'water contamination', 'water impurity', 'water management', 'water plastic', 'water pollution', 'water sewage', 'waterbourne disease','hurricane', 'sandy', 'storm', 'survivor', 'effort', 'u.s', 'east', 'flood', 'path', 'map','sound', 'metal', 'backyard', 'recording', 'hear', 'music', 'audio', 'cicada', 'scrap', 'temperature','climate', 'change', 'talk', 'week', 'need', 'say', 'study', 'ice', 'action', 'carbon','new', 'specie', 'york', 'farmer', 'discover', 'photo', 'energy', 'normal', 'animal', 'nyc','sea', 'rise', 'level', 'video', 'study', 'fall', 'photo', 'underwater', 'deep', 'melting','day', 'earth', 'mother', 'world', 'gift', 'photo', 'fall', 'green', 'celebrate', 'endanger','baby', 'photo', 'animal', 'week', 'panda', 'picture', 'zoo', 'elephant', 'gorilla', 'giraffes','animal', 'week', 'photo', 'picture', 'tiger', 'elephant', 'monkey', 'panda', 'lion', 'cub','use', 'park', 'photo', 'national', 'amazing', 'animal', 'odd', 'weather.com', 'way','time', 'celebrate', 'lapse', 'year', 'video', 'week', 'cool', 'wildlife', 'puppy', 'draw','keystone', 'xl', 'pipeline', 'sand', 'tar', 'obama', 'protester', 'arrest', 'student', 'department','extreme', 'weather', 'week', 'photo', 'hero', 'hill', 'hilarious', 'highlight', 'high', 'zoonose','photo', 'animal', 'life', 'nature', 'thing', 'pollution', 'world', 'big', 'storm', 'free','spill', 'bp', 'oil', 'trial', 'gulf', 'exxon', 'molasse', 'testify', 'halliburton', 'year','home', 'save', 'tip', 'money', 'orca', 'energy', 'rescue', 'winterize', 'food', 'abandon','public', 'kill', 'lion', 'preserve', 'transit', 'zoo', 'explorer', 'slaughter', 'cub', 'bear','project', 'reuse', 'diy', 'idea', 'old', 'shirt', 'craft', 'bag', 'make','green', 'eco', 'electric', 'friendly', 'tip', 'labor', 'burial', 'power', 'event', 'new','video', 'capture', 'make', 'camera', 'thing', 'pet', 'animal', 'puppy', 'kitten', 'panda','dog', 'cat', 'photo', 'video', 'pet', 'adorable', 'love', 'owner', 'rescue', 'head','say', 'water', 'study', 'food', 'global', 'warming', 'scientist', 'ban', 'new', 'highlight','oil', 'gas', 'california', 'future', 'natural', 'industry', 'fracke', 'plan', 'platform', 'drought','u.s', 'winter', 'fukushima', 'state', 'storm', 'hit', 'coast', 'american', 'outlook', 'hurricane']\n",
    "l = ['#algaebloom', '#chemicalspill', '#drinkingwatercontamination']\n",
    "\n",
    "l=\" OR \".join(l)\n",
    "search_terms = l\n",
    "new_search = search_terms + \"-filter:retweets\"\n",
    "print(new_search)\n",
    "tweets_df = selenium_client.get_tweets(new_search)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-env",
   "language": "python",
   "name": "research-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
