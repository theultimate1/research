{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "#from collections import defaultdict\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = []\n",
    "with open('datasets/water_tweets/water1.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets1.append(row)\n",
    "for tweet in tweets1:\n",
    "    mapping[tweet[2]].append(tweet[1])\n",
    "del tweets1[0]\n",
    "    \n",
    "tweets6 = []\n",
    "with open('datasets/water_tweets/water6.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets6.append(row)\n",
    "del tweets6[0]\n",
    "    \n",
    "tweets2 = []\n",
    "with open('datasets/water_tweets/water2.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets2.append(row)\n",
    "del tweets2[0]\n",
    "\n",
    "tweets4 = []\n",
    "with open('datasets/water_tweets/water4.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets4.append(row)\n",
    "del tweets4[0]\n",
    "\n",
    "tweets5 = []\n",
    "with open('datasets/water_tweets/water5.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets5.append(row)\n",
    "del tweets5[0]\n",
    "\n",
    "#tweets3 = []\n",
    "#with open('datasets/water_tweets/water3.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "#    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "#    line_count = 0\n",
    "#    for row in csv_reader:\n",
    "#        tweets3.append(row)\n",
    "#del tweets3[0]\n",
    "\n",
    "\n",
    "tweets7 = []\n",
    "with open('datasets/water_tweets/water7.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets7.append(row)\n",
    "del tweets7[0]\n",
    "    \n",
    "tweets8 = []\n",
    "with open('datasets/water_tweets/water8.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets8.append(row)\n",
    "del tweets8[0]\n",
    "\n",
    "tweets9 = []\n",
    "with open('datasets/water_tweets/water9.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets9.append(row)\n",
    "del tweets9[0]\n",
    "\n",
    "tweets10 = []\n",
    "with open('datasets/water_tweets/water10.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets10.append(row)\n",
    "del tweets10[0]\n",
    "    \n",
    "tweets11 = []\n",
    "with open('datasets/water_tweets/water11.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets11.append(row)\n",
    "del tweets11[0]\n",
    "\n",
    "tweets12 = []\n",
    "with open('datasets/water_tweets/water12.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets12.append(row)\n",
    "del tweets12[0]\n",
    "    \n",
    "tweets13 = []\n",
    "with open('datasets/water_tweets/water13.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets13.append(row)\n",
    "del tweets13[0]\n",
    "    \n",
    "tweets14 = []\n",
    "mapping = defaultdict(list)\n",
    "with open('datasets/water_tweets/water14.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets14.append(row)\n",
    "del tweets14[0]\n",
    "\n",
    "tweets15 = []\n",
    "with open('datasets/water_tweets/water15.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets15.append(row)\n",
    "del tweets15[0]\n",
    "\n",
    "tweets16 = []\n",
    "with open('datasets/water_tweets/water16.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets16.append(row)\n",
    "del tweets16[0]\n",
    "    \n",
    "tweets17 = []\n",
    "with open('datasets/water_tweets/water17.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets17.append(row)\n",
    "del tweets17[0]\n",
    "    \n",
    "tweets18 = []\n",
    "with open('datasets/water_tweets/water18.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets18.append(row)\n",
    "del tweets18[0]\n",
    "    \n",
    "tweets19 = []\n",
    "with open('datasets/water_tweets/water19.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets19.append(row)\n",
    "del tweets19[0]\n",
    "\n",
    "tweets20 = []\n",
    "with open('datasets/water_tweets/water20.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets20.append(row)\n",
    "del tweets20[0]\n",
    "\n",
    "tweets21 = []\n",
    "with open('datasets/water_tweets/water21.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets21.append(row)\n",
    "del tweets21[0]\n",
    "    \n",
    "tweets22 = []\n",
    "with open('datasets/water_tweets/water22.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets22.append(row)\n",
    "del tweets22[0]    \n",
    "\n",
    "tweets23 = []\n",
    "with open('datasets/water_tweets/water23.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets23.append(row)\n",
    "del tweets23[0]\n",
    "    \n",
    "tweets24 = []\n",
    "with open('datasets/water_tweets/water24.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets24.append(row)\n",
    "del tweets24[0]\n",
    "    \n",
    "tweets25 = []\n",
    "with open('datasets/water_tweets/water25.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets25.append(row)\n",
    "del tweets25[0]\n",
    "\n",
    "tweets26 = []\n",
    "with open('datasets/water_tweets/water26.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets26.append(row)\n",
    "del tweets26[0]\n",
    "\n",
    "tweets27 = []\n",
    "with open('datasets/water_tweets/water27.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets27.append(row)\n",
    "del tweets27[0]\n",
    "\n",
    "tweets28 = []\n",
    "with open('datasets/water_tweets/water28.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets28.append(row)\n",
    "del tweets28[0]\n",
    "\n",
    "tweets29 = []\n",
    "with open('datasets/water_tweets/water29.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets29.append(row)\n",
    "del tweets29[0]\n",
    "\n",
    "tweets30 = []\n",
    "with open('datasets/water_tweets/water30.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets30.append(row)\n",
    "del tweets30[0]\n",
    "\n",
    "tweets31 = []\n",
    "with open('datasets/water_tweets/water31.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets31.append(row)\n",
    "del tweets31[0]\n",
    "\n",
    "tweets32 = []\n",
    "with open('datasets/water_tweets/water32.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets32.append(row)\n",
    "del tweets32[0]\n",
    "\n",
    "tweets33 = []\n",
    "with open('datasets/water_tweets/water33.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets33.append(row)\n",
    "del tweets33[0]\n",
    "\n",
    "tweets34 = []\n",
    "with open('datasets/water_tweets/water34.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets34.append(row)\n",
    "del tweets34[0]\n",
    "\n",
    "tweets35 = []\n",
    "with open('datasets/water_tweets/water35.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets35.append(row)\n",
    "del tweets35[0]\n",
    "\n",
    "tweets36 = []\n",
    "with open('datasets/water_tweets/water36.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets36.append(row)\n",
    "del tweets36[0]\n",
    "\n",
    "tweets37 = []\n",
    "with open('datasets/water_tweets/water37.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets37.append(row)\n",
    "del tweets37[0]\n",
    "\n",
    "tweets38 = []\n",
    "with open('datasets/water_tweets/water38.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets38.append(row)\n",
    "del tweets38[0]\n",
    "\n",
    "tweets39 = []\n",
    "with open('datasets/water_tweets/water39.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets39.append(row)\n",
    "del tweets39[0]\n",
    "\n",
    "tweets40 = []\n",
    "with open('datasets/water_tweets/water40.csv',encoding=\"ISO-8859-1\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets40.append(row)\n",
    "del tweets40[0]\n",
    "\n",
    "tweets41 = []\n",
    "with open('datasets/water_tweets/water41.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets41.append(row)\n",
    "del tweets41[0]\n",
    "\n",
    "tweets42 = []\n",
    "with open('datasets/water_tweets/water42.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets42.append(row)\n",
    "del tweets42[0]  \n",
    "\n",
    "tweets43 = []\n",
    "with open('datasets/water_tweets/water43.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets43.append(row)\n",
    "del tweets43[0]\n",
    "\n",
    "tweets44 = []\n",
    "with open('datasets/water_tweets/water44.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets44.append(row)\n",
    "del tweets44[0]\n",
    "\n",
    "tweets45 = []\n",
    "with open('datasets/water_tweets/water45.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets45.append(row)\n",
    "del tweets45[0]\n",
    "\n",
    "tweets46 = []\n",
    "with open('datasets/water_tweets/water46.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets46.append(row)\n",
    "del tweets46[0]\n",
    "\n",
    "tweets47 = []\n",
    "with open('datasets/water_tweets/water47.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets47.append(row)\n",
    "del tweets47[0]\n",
    "\n",
    "tweets48 = []\n",
    "with open('datasets/water_tweets/water48.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets48.append(row)\n",
    "del tweets48[0]\n",
    "\n",
    "tweets49 = []\n",
    "with open('datasets/water_tweets/water49.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets49.append(row)\n",
    "del tweets49[0]\n",
    "\n",
    "tweets50 = []\n",
    "with open('datasets/water_tweets/water50.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets50.append(row)\n",
    "del tweets50[0]\n",
    "\n",
    "tweets51 = []\n",
    "with open('datasets/water_tweets/water51.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets51.append(row)\n",
    "del tweets51[0]\n",
    "\n",
    "tweets52 = []\n",
    "with open('datasets/water_tweets/water52.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets52.append(row)\n",
    "del tweets52[0]\n",
    "\n",
    "tweets53 = []\n",
    "with open('datasets/water_tweets/water53.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets53.append(row)\n",
    "del tweets53[0]\n",
    "\n",
    "tweets54 = []\n",
    "with open('datasets/water_tweets/water54.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets54.append(row)\n",
    "del tweets54[0]\n",
    "\n",
    "tweets55 = []\n",
    "with open('datasets/water_tweets/water55.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets55.append(row)\n",
    "del tweets55[0]\n",
    "\n",
    "tweets56 = []\n",
    "with open('datasets/water_tweets/water56.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets56.append(row)\n",
    "del tweets56[0]\n",
    "\n",
    "tweets57 = []\n",
    "with open('datasets/water_tweets/water57.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets57.append(row)\n",
    "del tweets57[0]\n",
    "\n",
    "tweets58 = []\n",
    "with open('datasets/water_tweets/water58.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets58.append(row)\n",
    "del tweets58[0]\n",
    "\n",
    "tweets59 = []\n",
    "with open('datasets/water_tweets/water59.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets59.append(row)\n",
    "del tweets59[0]\n",
    "\n",
    "tweets60 = []\n",
    "with open('datasets/water_tweets/water60.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets60.append(row)\n",
    "del tweets60[0]\n",
    "\n",
    "tweets61 = []\n",
    "with open('datasets/water_tweets/water61.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets61.append(row)\n",
    "del tweets61[0]\n",
    "\n",
    "tweets62 = []\n",
    "with open('datasets/water_tweets/water62.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets62.append(row)\n",
    "del tweets62[0]\n",
    "\n",
    "tweets63 = []\n",
    "with open('datasets/water_tweets/water63.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets63.append(row)\n",
    "del tweets63[0]\n",
    "\n",
    "tweets64 = []\n",
    "with open('datasets/water_tweets/water64.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets64.append(row)\n",
    "del tweets64[0]\n",
    "\n",
    "tweets65 = []\n",
    "with open('datasets/water_tweets/water65.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets65.append(row)\n",
    "del tweets65[0]\n",
    "\n",
    "tweets66 = []\n",
    "with open('datasets/water_tweets/water66.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets66.append(row)\n",
    "del tweets66[0]\n",
    "\n",
    "tweets67 = []\n",
    "with open('datasets/water_tweets/water67.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets67.append(row)\n",
    "del tweets67[0]\n",
    "\n",
    "tweets68 = []\n",
    "with open('datasets/water_tweets/water68.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets68.append(row)\n",
    "del tweets68[0]\n",
    "\n",
    "tweets69 = []\n",
    "with open('datasets/water_tweets/water69.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets69.append(row)\n",
    "del tweets69[0]\n",
    "\n",
    "tweets70 = []\n",
    "with open('datasets/water_tweets/water70.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets70.append(row)\n",
    "del tweets70[0]\n",
    "\n",
    "tweets71 = []\n",
    "with open('datasets/water_tweets/water71.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets71.append(row)\n",
    "del tweets71[0]\n",
    "\n",
    "tweets72 = []\n",
    "with open('datasets/water_tweets/water72.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets72.append(row)\n",
    "del tweets72[0]\n",
    "\n",
    "tweets73 = []\n",
    "with open('datasets/water_tweets/water73.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets73.append(row)\n",
    "del tweets73[0]\n",
    "\n",
    "tweets74 = []\n",
    "with open('datasets/water_tweets/water74.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets74.append(row)\n",
    "del tweets74[0]\n",
    "\n",
    "tweets75 = []\n",
    "with open('datasets/water_tweets/water75.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets75.append(row)\n",
    "del tweets75[0]\n",
    "\n",
    "tweets76 = []\n",
    "with open('datasets/water_tweets/water76.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets76.append(row)\n",
    "del tweets76[0]\n",
    "\n",
    "tweets77 = []\n",
    "with open('datasets/water_tweets/water77.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets77.append(row)\n",
    "del tweets77[0]\n",
    "\n",
    "tweets78 = []\n",
    "with open('datasets/water_tweets/water78.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets78.append(row)\n",
    "del tweets78[0]\n",
    "\n",
    "tweets79 = []\n",
    "with open('datasets/water_tweets/water79.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets79.append(row)\n",
    "del tweets79[0]\n",
    "\n",
    "tweets80 = []\n",
    "with open('datasets/water_tweets/water80.csv', encoding = 'ISO-8859-1') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ';')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        tweets80.append(row)\n",
    "del tweets80[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_csv_list = [tweets1, tweets2, tweets4, tweets5, tweets6, tweets7, tweets8, tweets9,\n",
    "                 tweets10, tweets11, tweets12, tweets13, tweets14, tweets15, tweets16, tweets17, tweets18,\n",
    "                 tweets19, tweets20, tweets21, tweets22, tweets23, tweets24, tweets25, tweets26, tweets27,\n",
    "                 tweets28, tweets29, tweets30, tweets31, tweets32, tweets33, tweets34, tweets35, tweets36,\n",
    "                 tweets37, tweets38, tweets39, tweets40, tweets41, tweets42, tweets43, tweets44, tweets45,\n",
    "                 tweets46, tweets47, tweets48, tweets49, tweets50, tweets51, tweets52, tweets53, tweets54,\n",
    "                 tweets55, tweets56, tweets57, tweets58, tweets59, tweets60, tweets61, tweets62, tweets63,\n",
    "                 tweets64, tweets65, tweets66, tweets67, tweets68, tweets69, tweets70, tweets71, tweets72,\n",
    "                 tweets73, tweets74, tweets75, tweets76, tweets77, tweets78, tweets79, tweets80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['flash flood', '1.14E+18', \"@LeslieWalden6 @MookieTheBrave @AngusMcPussPuss @AngelaStillwell @cat_samson @arkantart @Biscuit_Meow @duchess_meow @TobiasandJasper @goodman_carina It's cwazy!! Mom tiwed of seeing flash flood warnings fwom The Weather Channel pop up on her phone evewyday. She appweciates the warning, but she knows which aweas are pwone to flooding.ð\\x9f\\x98¼ð\\x9f\\x98¼\", '6/25/2019 20:45', '0'], ['flash flood', '1.14E+18', '4 PASSES to FLASH FLOOD WATER PARK in Battle Creek, MICHIGAN - 2019 season!!! $12.00 | #WaterparkTickets | https://t.co/tIumVg5T0d Grab Your Tickets https://t.co/UQNz5zZ7vC', '6/25/2019 20:28', '0'], ['flash flood', '1.14E+18', 'So the maintenance men at my apartment complex are leaf blowing during a flash flood warning... https://t.co/YkWkVzTvSy', '6/25/2019 20:21', '0'], ['flash flood', '1.14E+18', '.@NWStulsa issued 1,530 flood/flash flood products in May 2019 alone!  Includes new warnings/advisories + all follow up statements #okwx #arwx https://t.co/3M9GfJyuez', '6/25/2019 20:07', '0'], ['flash flood', '1.14E+18', 'They might not call it a #climatedebate, but considering that the venue where 20 Democrats are meeting in Miami this week was once inundated during a flash flood, it kinda is. https://t.co/xlZ66jHMXr', '6/25/2019 19:55', '0']]\n"
     ]
    }
   ],
   "source": [
    "all_tweets = []\n",
    "for i in range(len(tweet_csv_list)):\n",
    "    for j in range(len(tweet_csv_list[i])):\n",
    "        all_tweets.append(tweet_csv_list[i][j])\n",
    "        \n",
    "print(all_tweets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108136\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered_tweets = pd.DataFrame(data = all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flash flood</td>\n",
       "      <td>1.14E+18</td>\n",
       "      <td>@LeslieWalden6 @MookieTheBrave @AngusMcPussPus...</td>\n",
       "      <td>6/25/2019 20:45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flash flood</td>\n",
       "      <td>1.14E+18</td>\n",
       "      <td>4 PASSES to FLASH FLOOD WATER PARK in Battle C...</td>\n",
       "      <td>6/25/2019 20:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flash flood</td>\n",
       "      <td>1.14E+18</td>\n",
       "      <td>So the maintenance men at my apartment complex...</td>\n",
       "      <td>6/25/2019 20:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flash flood</td>\n",
       "      <td>1.14E+18</td>\n",
       "      <td>.@NWStulsa issued 1,530 flood/flash flood prod...</td>\n",
       "      <td>6/25/2019 20:07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flash flood</td>\n",
       "      <td>1.14E+18</td>\n",
       "      <td>They might not call it a #climatedebate, but c...</td>\n",
       "      <td>6/25/2019 19:55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword  tweet_id                                              tweet  \\\n",
       "0  flash flood  1.14E+18  @LeslieWalden6 @MookieTheBrave @AngusMcPussPus...   \n",
       "1  flash flood  1.14E+18  4 PASSES to FLASH FLOOD WATER PARK in Battle C...   \n",
       "2  flash flood  1.14E+18  So the maintenance men at my apartment complex...   \n",
       "3  flash flood  1.14E+18  .@NWStulsa issued 1,530 flood/flash flood prod...   \n",
       "4  flash flood  1.14E+18  They might not call it a #climatedebate, but c...   \n",
       "\n",
       "        time_stamp retweets  \n",
       "0  6/25/2019 20:45        0  \n",
       "1  6/25/2019 20:28        0  \n",
       "2  6/25/2019 20:21        0  \n",
       "3  6/25/2019 20:07        0  \n",
       "4  6/25/2019 19:55        0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered_tweets = gathered_tweets.iloc[:, 0:5]\n",
    "gathered_tweets.columns = ['keyword', 'tweet_id', 'tweet', 'time_stamp', 'retweets']\n",
    "gathered_tweets = gathered_tweets.drop_duplicates(subset = ['tweet'], keep = 'first').reset_index()\n",
    "gathered_tweets = gathered_tweets.iloc[:, 1:]\n",
    "gathered_tweets = gathered_tweets[gathered_tweets['keyword'] != 'pcb']\n",
    "gathered_tweets = gathered_tweets[gathered_tweets['keyword'] != 'benzene']\n",
    "print(len(gathered_tweets))\n",
    "gathered_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flash flood' 'water contamination' 'pipe leak' 'dry well'\n",
      " 'water management' 'drought' 'groundwater contamination'\n",
      " 'lake contamination' 'water pollution' 'water impurity'\n",
      " 'stream contamination' 'water sewage' 'lake pollution'\n",
      " 'groundwater pollution' 'chemical spill' 'industrial solvents'\n",
      " 'metal hydroxide' 'waterbourne disease' 'drinking water contamination'\n",
      " 'industrial pollution' 'coal ash water' 'e-coli' 'lead water'\n",
      " 'waste water' 'water and sanitation' 'toxic waste water' 'waste spill'\n",
      " 'water plastic' '#flashflood' '#watercontamination' '#pipeleak'\n",
      " '#watermanagement' '#drought' '#waterpollution'\n",
      " '#groundwatercontamination' '#wastewater' '#waterandsanitation'\n",
      " '#industrialpollution' '#drinkingwatercontamination' '#chemicalspill'\n",
      " '#ecoli' 'ecoli' 'river contamination' 'algae bloom' 'untreated waste'\n",
      " 'marine plastic pollution' 'oil spill' 'drinking water' '#algaebloom'\n",
      " '#oilspill']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(gathered_tweets.keyword.unique())\n",
    "print(gathered_tweets.keyword.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#algaebloom</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#chemicalspill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#drinkingwatercontamination</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#drought</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ecoli</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#flashflood</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#groundwatercontamination</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#industrialpollution</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#oilspill</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#pipeleak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#wastewater</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#waterandsanitation</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>#watercontamination</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#watermanagement</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#waterpollution</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>algae bloom</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chemical spill</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>coal ash water</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>drinking water</td>\n",
       "      <td>2909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>drinking water contamination</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>drought</td>\n",
       "      <td>7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dry well</td>\n",
       "      <td>4871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>e-coli</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ecoli</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>flash flood</td>\n",
       "      <td>4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>groundwater contamination</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>groundwater pollution</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>industrial pollution</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>industrial solvents</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lake contamination</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lake pollution</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lead water</td>\n",
       "      <td>3485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>marine plastic pollution</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>metal hydroxide</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>oil spill</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pipe leak</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>river contamination</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>stream contamination</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>toxic waste water</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>untreated waste</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>waste spill</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>waste water</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>water and sanitation</td>\n",
       "      <td>2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>water contamination</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>water impurity</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>water management</td>\n",
       "      <td>3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>water plastic</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>water pollution</td>\n",
       "      <td>3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>water sewage</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>waterbourne disease</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         keyword  tweet_id\n",
       "0                    #algaebloom        28\n",
       "1                 #chemicalspill         1\n",
       "2    #drinkingwatercontamination         2\n",
       "3                       #drought       540\n",
       "4                         #ecoli       104\n",
       "5                    #flashflood       484\n",
       "6      #groundwatercontamination         4\n",
       "7           #industrialpollution         3\n",
       "8                      #oilspill       103\n",
       "9                      #pipeleak         1\n",
       "10                   #wastewater       585\n",
       "11           #waterandsanitation         6\n",
       "12           #watercontamination        12\n",
       "13              #watermanagement       336\n",
       "14               #waterpollution       198\n",
       "15                   algae bloom      1145\n",
       "16                chemical spill       450\n",
       "17                coal ash water       165\n",
       "18                drinking water      2909\n",
       "19  drinking water contamination       120\n",
       "20                       drought      7435\n",
       "21                      dry well      4871\n",
       "22                        e-coli       658\n",
       "23                         ecoli       868\n",
       "24                   flash flood      4286\n",
       "25     groundwater contamination       201\n",
       "26         groundwater pollution       146\n",
       "27          industrial pollution       902\n",
       "28           industrial solvents        23\n",
       "29            lake contamination        52\n",
       "30                lake pollution       631\n",
       "31                    lead water      3485\n",
       "32      marine plastic pollution       211\n",
       "33               metal hydroxide         6\n",
       "34                     oil spill      1441\n",
       "35                     pipe leak       562\n",
       "36           river contamination        39\n",
       "37          stream contamination        50\n",
       "38             toxic waste water       336\n",
       "39               untreated waste        66\n",
       "40                   waste spill       221\n",
       "41                   waste water      3010\n",
       "42          water and sanitation      2268\n",
       "43           water contamination      1675\n",
       "44                water impurity        40\n",
       "45              water management      3884\n",
       "46                 water plastic       904\n",
       "47               water pollution      3780\n",
       "48                  water sewage      1173\n",
       "49           waterbourne disease         2"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_key = gathered_tweets.groupby('keyword').count().reset_index()\n",
    "by_key = by_key.iloc[:, 0:2]\n",
    "by_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered_tweets = gathered_tweets.iloc[:, 1:]\n",
    "gathered_tweets.to_csv(r'datasets\\water_tweets\\un_gathered_h2o_tweets.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
