{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Extraction of Zip Files and JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import textblob\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Samples\n",
    "Not super useful as they are UK 2015 Election related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hopeless for tmr :(',\n",
       " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\",\n",
       " '@Hegelbon That heart sliding into the waste basket. :(',\n",
       " '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
       " 'Dang starting next week I have \"work\" :(']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.strings()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hopeless', 'for', 'tmr', ':(', 'Everything', 'in', 'the', 'kids', 'section', 'of']\n"
     ]
    }
   ],
   "source": [
    "tweets = twitter_samples.tokenized()\n",
    "tweet_dict = []\n",
    "for i in range(len(tweets)):\n",
    "    for j in range(len(tweets[i])):\n",
    "        tweet_dict.append(tweets[i][j])\n",
    "\n",
    "\n",
    "print(tweet_dict[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(twitter_samples.strings()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>@LeslieWalden6 @MookieTheBrave @AngusMcPussPus...</td>\n",
       "      <td>6/25/2019 20:45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>4 PASSES to FLASH FLOOD WATER PARK in Battle C...</td>\n",
       "      <td>6/25/2019 20:28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>So the maintenance men at my apartment complex...</td>\n",
       "      <td>6/25/2019 20:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>.@NWStulsa issued 1,530 flood/flash flood prod...</td>\n",
       "      <td>6/25/2019 20:07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>They might not call it a #climatedebate, but c...</td>\n",
       "      <td>6/25/2019 19:55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                                              tweet  \\\n",
       "0  1.140000e+18  @LeslieWalden6 @MookieTheBrave @AngusMcPussPus...   \n",
       "1  1.140000e+18  4 PASSES to FLASH FLOOD WATER PARK in Battle C...   \n",
       "2  1.140000e+18  So the maintenance men at my apartment complex...   \n",
       "3  1.140000e+18  .@NWStulsa issued 1,530 flood/flash flood prod...   \n",
       "4  1.140000e+18  They might not call it a #climatedebate, but c...   \n",
       "\n",
       "        time_stamp  retweets  \n",
       "0  6/25/2019 20:45         0  \n",
       "1  6/25/2019 20:28         0  \n",
       "2  6/25/2019 20:21         0  \n",
       "3  6/25/2019 20:07         0  \n",
       "4  6/25/2019 19:55         0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_tweets = pd.read_csv('datasets/water_tweets/un_gathered_h2o_tweets.csv', encoding = 'ISO-8859-1', delimiter = ';')\n",
    "scraped_tweets = scraped_tweets.iloc[:, 1:]\n",
    "scraped_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\debro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@LeslieWalden6 @MookieTheBrave @AngusMcPussPuss @AngelaStillwell @cat_samson @arkantart @Biscuit_Meow @duchess_meow @TobiasandJasper @goodman_carina It's cwazy!! Mom tiwed of seeing flash flood warnings fwom The Weather Channel pop up on her phone evewyday. She appweciates the warning, but she knows which aweas are pwone to flooding.Ã°Â\\x9fÂ\\x98Â¼Ã°Â\\x9fÂ\\x98Â¼\",\n",
       " '4 PASSES to FLASH FLOOD WATER PARK in Battle Creek, MICHIGAN - 2019 season!!! $12.00 | #WaterparkTickets | https://t.co/tIumVg5T0d Grab Your Tickets https://t.co/UQNz5zZ7vC',\n",
       " 'So the maintenance men at my apartment complex are leaf blowing during a flash flood warning... https://t.co/YkWkVzTvSy',\n",
       " '.@NWStulsa issued 1,530 flood/flash flood products in May 2019 alone!  Includes new warnings/advisories + all follow up statements #okwx #arwx https://t.co/3M9GfJyuez',\n",
       " 'They might not call it a #climatedebate, but considering that the venue where 20 Democrats are meeting in Miami this week was once inundated during a flash flood, it kinda is. https://t.co/xlZ66jHMXr']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = np.array(scraped_tweets.tweet.astype(str))\n",
    "\n",
    "tweet_list = []\n",
    "for i in range(len(tweet_text)):\n",
    "    tweet = tweet_text[i]\n",
    "    tweet_list.append(tweet)\n",
    "tweet_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "tweets = np.array(tweet_list)\n",
    "tweet_list = []\n",
    "for t in range(len(tweets)):\n",
    "    new = TextBlob(tweets[t])\n",
    "    tweet_list.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48121\n"
     ]
    }
   ],
   "source": [
    "rel_h2o_words = []\n",
    "for i in range(len(tweet_list)):\n",
    "    tweet_i = tweet_list[i]\n",
    "    new_words = tweet_i.words\n",
    "    rel_h2o_words.append(new_words)\n",
    "    \n",
    "print(len(rel_h2o_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_words = np.array(tweet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "rel_h2o_words = np.array(list(chain(*rel_h2o_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = np.concatenate([tweet_words, rel_h2o_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2387635\n"
     ]
    }
   ],
   "source": [
    "print(len(new_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186908\n"
     ]
    }
   ],
   "source": [
    "unique_dict = np.unique(new_dict)\n",
    "print(len(unique_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
